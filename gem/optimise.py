"""A set of routines implementing various transformations on GEM
expressions."""

from __future__ import absolute_import, print_function, division
from six.moves import map, range, zip

from collections import deque
from functools import reduce
from itertools import permutations

import numpy
from singledispatch import singledispatch

from gem.node import Memoizer, MemoizerArg, reuse_if_untouched, reuse_if_untouched_arg
from gem.gem import (Node, Terminal, Failure, Identity, Literal, Zero,
                     Product, Sum, Comparison, Conditional, Index,
                     VariableIndex, Indexed, FlexiblyIndexed,
                     IndexSum, ComponentTensor, ListTensor, Delta,
                     partial_indexed)
from gem.utils import OrderedSet


@singledispatch
def literal_rounding(node, self):
    """Perform FFC rounding of FIAT tabulation matrices on the literals of
    a GEM expression.

    :arg node: root of the expression
    :arg self: function for recursive calls
    """
    raise AssertionError("cannot handle type %s" % type(node))


literal_rounding.register(Node)(reuse_if_untouched)


@literal_rounding.register(Literal)
def literal_rounding_literal(node, self):
    table = node.array
    epsilon = self.epsilon
    # Copied from FFC (ffc/quadrature/quadratureutils.py)
    table[abs(table) < epsilon] = 0
    table[abs(table - 1.0) < epsilon] = 1.0
    table[abs(table + 1.0) < epsilon] = -1.0
    table[abs(table - 0.5) < epsilon] = 0.5
    table[abs(table + 0.5) < epsilon] = -0.5
    return Literal(table)


def ffc_rounding(expression, epsilon):
    """Perform FFC rounding of FIAT tabulation matrices on the literals of
    a GEM expression.

    :arg expression: GEM expression
    :arg epsilon: tolerance limit for rounding
    """
    mapper = Memoizer(literal_rounding)
    mapper.epsilon = epsilon
    return mapper(expression)


@singledispatch
def replace_indices(node, self, subst):
    """Replace free indices in a GEM expression.

    :arg node: root of the expression
    :arg self: function for recursive calls
    :arg subst: tuple of pairs; each pair is a substitution
                rule with a free index to replace and an index to
                replace with.
    """
    raise AssertionError("cannot handle type %s" % type(node))


replace_indices.register(Node)(reuse_if_untouched_arg)


@replace_indices.register(Delta)
def replace_indices_delta(node, self, subst):
    substitute = dict(subst)
    i = substitute.get(node.i, node.i)
    j = substitute.get(node.j, node.j)
    if i == node.i and j == node.j:
        return node
    else:
        return Delta(i, j)


@replace_indices.register(Indexed)
def replace_indices_indexed(node, self, subst):
    child, = node.children
    substitute = dict(subst)
    multiindex = tuple(substitute.get(i, i) for i in node.multiindex)
    if isinstance(child, ComponentTensor):
        # Indexing into ComponentTensor
        # Inline ComponentTensor and augment the substitution rules
        substitute.update(zip(child.multiindex, multiindex))
        return self(child.children[0], tuple(sorted(substitute.items())))
    else:
        # Replace indices
        new_child = self(child, subst)
        if new_child == child and multiindex == node.multiindex:
            return node
        else:
            return Indexed(new_child, multiindex)


@replace_indices.register(FlexiblyIndexed)
def replace_indices_flexiblyindexed(node, self, subst):
    child, = node.children
    assert isinstance(child, Terminal)
    assert not child.free_indices

    substitute = dict(subst)
    dim2idxs = tuple(
        (offset, tuple((substitute.get(i, i), s) for i, s in idxs))
        for offset, idxs in node.dim2idxs
    )

    if dim2idxs == node.dim2idxs:
        return node
    else:
        return FlexiblyIndexed(child, dim2idxs)


def filtered_replace_indices(node, self, subst):
    """Wrapper for :func:`replace_indices`.  At each call removes
    substitution rules that do not apply."""
    filtered_subst = tuple((k, v) for k, v in subst if k in node.free_indices)
    return replace_indices(node, self, filtered_subst)


def remove_componenttensors(expressions):
    """Removes all ComponentTensors in multi-root expression DAG."""
    mapper = MemoizerArg(filtered_replace_indices)
    return [mapper(expression, ()) for expression in expressions]


def _select_expression(expressions, index):
    """Helper function to select an expression from a list of
    expressions with an index.  This function expect sanitised input,
    one should normally call :py:func:`select_expression` instead.

    :arg expressions: a list of expressions
    :arg index: an index (free, fixed or variable)
    :returns: an expression
    """
    expr = expressions[0]
    if all(e == expr for e in expressions):
        return expr

    cls = type(expr)
    if all(type(e) == cls for e in expressions):
        if not cls.__front__ and not cls.__back__:
            assert all(len(e.children) == len(expr.children) for e in expressions)
            assert len(expr.children) > 0

            return expr.reconstruct(*[_select_expression(nth_children, index)
                                      for nth_children in zip(*[e.children
                                                                for e in expressions])])
        elif issubclass(cls, Indexed):
            assert all(e.multiindex == expr.multiindex for e in expressions)
            return Indexed(_select_expression([e.children[0]
                                               for e in expressions], index), expr.multiindex)
        elif issubclass(cls, (Literal, Failure)):
            return partial_indexed(ListTensor(expressions), (index,))
        else:
            assert False
    else:
        assert False


def select_expression(expressions, index):
    """Select an expression from a list of expressions with an index.
    Semantically equivalent to

        partial_indexed(ListTensor(expressions), (index,))

    but has a much more optimised implementation.

    :arg expressions: a list of expressions of the same shape
    :arg index: an index (free, fixed or variable)
    :returns: an expression of the same shape as the given expressions
    """
    # Check arguments
    shape = expressions[0].shape
    assert all(e.shape == shape for e in expressions)

    # Sanitise input expressions
    alpha = tuple(Index() for s in shape)
    exprs = remove_componenttensors([Indexed(e, alpha) for e in expressions])

    # Factor the expressions recursively and convert result
    selected = _select_expression(exprs, index)
    return ComponentTensor(selected, alpha)


@singledispatch
def _pull_delta_from_listtensor(node, self):
    """Pull common delta factors out of ListTensor entries.

    :arg node: root of the expression
    :arg self: function for recursive calls
    """
    raise AssertionError("cannot handle type %s" % type(node))


_pull_delta_from_listtensor.register(Node)(reuse_if_untouched)


@_pull_delta_from_listtensor.register(ListTensor)
def _pull_delta_from_listtensor_listtensor(node, self):
    # Separate Delta nodes from other expressions
    deltaz = []
    rests = []

    for child in node.children:
        deltas = OrderedSet()
        others = []

        # Traverse Product tree
        queue = deque([child])
        while queue:
            expr = queue.popleft()
            if isinstance(expr, Product):
                queue.extend(expr.children)
            elif isinstance(expr, Delta):
                assert expr not in deltas
                deltas.add(expr)
            else:
                others.append(self(expr))  # looks for more ListTensors inside

        deltaz.append(deltas)
        rests.append(reduce(Product, others))

    # Factor out common Delta factors
    common_deltas = set.intersection(*[set(ds) for ds in deltaz])
    deltaz = [[d for d in ds if d not in common_deltas] for ds in deltaz]

    # Rebuild ListTensor
    new_children = [reduce(Product, ds, rest)
                    for ds, rest in zip(deltaz, rests)]
    result = node.reconstruct(*new_children)

    # Apply common Delta factors
    if common_deltas:
        alpha = tuple(Index(extent=d) for d in result.shape)
        expr = reduce(Product, common_deltas, Indexed(result, alpha))
        result = ComponentTensor(expr, alpha)
    return result


def pull_delta_from_listtensor(expression):
    """Pull common delta factors out of ListTensor entries."""
    mapper = Memoizer(_pull_delta_from_listtensor)
    return mapper(expression)


def contraction(expression, logger=None):
    """Optimise the contractions of the tensor product at the root of
    the expression, including:

    - IndexSum-Delta cancellation
    - Sum factorisation

    This routine was designed with finite element coefficient
    evaluation in mind.
    """
    # Pull Delta nodes out of annoying ListTensors, and eliminate
    # annoying ComponentTensors
    expression, = remove_componenttensors([expression])
    expression = pull_delta_from_listtensor(expression)
    expression, = remove_componenttensors([expression])

    # Flatten a product tree
    sum_indices = []
    factors = []

    queue = deque([expression])
    while queue:
        expr = queue.popleft()
        if isinstance(expr, IndexSum):
            queue.append(expr.children[0])
            sum_indices.extend(expr.multiindex)
        elif isinstance(expr, Product):
            queue.extend(expr.children)
        else:
            factors.append(expr)

    # Try to eliminate Delta nodes
    delta_queue = [(f, index)
                   for f in factors if isinstance(f, Delta)
                   for index in (f.i, f.j) if index in sum_indices]
    while delta_queue:
        delta, from_ = delta_queue[0]
        to_, = list({delta.i, delta.j} - {from_})

        sum_indices.remove(from_)

        mapper = MemoizerArg(filtered_replace_indices)
        factors = [mapper(e, ((from_, to_),)) for e in factors]

        delta_queue = [(f, index)
                       for f in factors if isinstance(f, Delta)
                       for index in (f.i, f.j) if index in sum_indices]

    # Drop ones
    factors = [e for e in factors if e != Literal(1)]

    # Sum factorisation
    def construct(ordering):
        """Construct tensor product from a given ordering."""
        # deps: Indices for each term that need to be summed over.
        deps = [set(sum_indices) & set(factor.free_indices)
                for factor in ordering]

        # scan_deps: Scan deps to the right with union operation.
        scan_deps = [None] * len(ordering)
        scan_deps[0] = deps[0]
        for i in range(1, len(ordering)):
            scan_deps[i] = scan_deps[i - 1] | deps[i]

        # sum_at: What IndexSum nodes should be inserted before each
        # term.  An IndexSum binds all terms to its right.
        sum_at = [None] * len(ordering)
        sum_at[0] = scan_deps[0]
        for i in range(1, len(ordering)):
            sum_at[i] = scan_deps[i] - scan_deps[i - 1]

        # Construct expression and count floating-point operations
        expr = None
        flops = 0
        for s, f in reversed(list(zip(sum_at, ordering))):
            if expr is None:
                expr = f
            else:
                expr = Product(f, expr)
                flops += numpy.prod([i.extent for i in expr.free_indices], dtype=int)
            if s:
                flops += numpy.prod([i.extent for i in s])
            expr = IndexSum(expr, tuple(i for i in sum_indices if i in s))
        return expr, flops

    if len(factors) <= 5:
        expression = None
        best_flops = numpy.inf

        for ordering in permutations(factors):
            expr, flops = construct(ordering)
            if flops < best_flops:
                expression = expr
                best_flops = flops
    else:
        # Cheap heuristic
        logger.warning("Unexpectedly many terms for sum factorisation: %d"
                       "; falling back on cheap heuristic.", len(factors))

        def key(factor):
            return len(set(sum_indices) & set(factor.free_indices))
        ordering = sorted(factors, key=key)

        expression, flops = construct(ordering)

    return expression


@singledispatch
def _replace_delta(node, self):
    raise AssertionError("cannot handle type %s" % type(node))


_replace_delta.register(Node)(reuse_if_untouched)


@_replace_delta.register(Delta)
def _replace_delta_delta(node, self):
    i, j = node.i, node.j

    if isinstance(i, Index) or isinstance(j, Index):
        if isinstance(i, Index) and isinstance(j, Index):
            assert i.extent == j.extent
        if isinstance(i, Index):
            assert i.extent is not None
            size = i.extent
        if isinstance(j, Index):
            assert j.extent is not None
            size = j.extent
        return Indexed(Identity(size), (i, j))
    else:
        def expression(index):
            if isinstance(index, int):
                return Literal(index)
            elif isinstance(index, VariableIndex):
                return index.expression
            else:
                raise ValueError("Cannot convert running index to expression.")
        e_i = expression(i)
        e_j = expression(j)
        return Conditional(Comparison("==", e_i, e_j), Literal(1), Zero())


def replace_delta(expressions):
    """Lowers all Deltas in a multi-root expression DAG."""
    mapper = Memoizer(_replace_delta)
    return list(map(mapper, expressions))


@singledispatch
def _unroll_indexsum(node, self):
    """Unrolls IndexSums below a certain extent.

    :arg node: root of the expression
    :arg self: function for recursive calls
    """
    raise AssertionError("cannot handle type %s" % type(node))


_unroll_indexsum.register(Node)(reuse_if_untouched)


@_unroll_indexsum.register(IndexSum)  # noqa
def _(node, self):
    unroll = tuple(index for index in node.multiindex
                   if index.extent <= self.max_extent)
    if unroll:
        # Unrolling
        summand = self(node.children[0])
        shape = tuple(index.extent for index in unroll)
        unrolled = reduce(Sum,
                          (Indexed(ComponentTensor(summand, unroll), alpha)
                           for alpha in numpy.ndindex(shape)),
                          Zero())
        return IndexSum(unrolled, tuple(index for index in node.multiindex
                                        if index not in unroll))
    else:
        return reuse_if_untouched(node, self)


def unroll_indexsum(expressions, max_extent):
    """Unrolls IndexSums below a specified extent.

    :arg expressions: list of expression DAGs
    :arg max_extent: maximum extent for which IndexSums are unrolled
    :returns: list of expression DAGs with some unrolled IndexSums
    """
    mapper = Memoizer(_unroll_indexsum)
    mapper.max_extent = max_extent
    return list(map(mapper, expressions))
